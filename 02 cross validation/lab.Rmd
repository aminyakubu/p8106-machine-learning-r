---
title: "Cross validation & Bootstrap"
author: "Amin Yakubu"
date: "2/11/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## The Validation Set Approach

We explore the use of the validation set approach in order to estimate the test error rates that result from fitting various linear models on the Auto data set

```{r}
library(ISLR)
```

We begin by using the sample() function to split the set of observations into two halves, by selecting a random subset of 196 observations out of sample() the original 392 observations. We refer to these observations as the training
set.

```{r}
set.seed(1)
train = sample(392, 196)
```

We then use the subset option in lm() to fit a linear regression using only the observations corresponding to the training set

```{r}
data("Auto")

lm.fit = lm(mpg ~ horsepower, data = Auto, subset = train )
```

We now use the predict() function to estimate the response for all 392 observations, and we use the mean() function to calculate the MSE of the 196 observations in the validation set. Note that the -train index below selects only the observations that are not in the training set.

```{r}
attach(Auto)
mean((mpg - predict(lm.fit, Auto))[-train]^2)
```

Therefore, the estimated test MSE for the linear regression fit is 26.14. 

We can use the poly() function to estimate the test error for the quadratic and cubic regressions.

```{r}
lm.fit2 = lm(mpg ~ poly(horsepower, 2), data = Auto, subset = train)
mean((mpg - predict(lm.fit2, Auto))[-train]^2)

lm.fit3 = lm(mpg ~ poly(horsepower, 3), data = Auto, subset = train)
mean((mpg - predict(lm.fit3, Auto))[-train]^2)
```

These error rates are 19.82 and 19.78, respectively. 
If we choose a different training set instead, then we will obtain somewhat different errors on the validation set

```{r}
set.seed(2)
train = sample(392,196)

lm.fit = lm(mpg ~ horsepower, subset = train)
mean((mpg - predict(lm.fit,Auto))[-train]^2)


lm.fit2 = lm(mpg ~ poly(horsepower ,2),data = Auto, subset = train) 
mean((mpg - predict(lm.fit2 ,Auto))[-train]^2)

lm.fit3 = lm(mpg ~ poly(horsepower ,3), data = Auto,subset = train) 
mean((mpg - predict(lm.fit3, Auto))[-train]^2)


```

Using this split of the observations into a training set and a validation set, we find that the validation set error rates for the models with linear, quadratic, and cubic terms are 23.30, 18.90, and 19.26, respectively.

These results are consistent with our previous findings: a model that predicts mpg using a quadratic function of horsepower performs better than a model that involves only a linear function of horsepower, and there is little evidence in favor of a model that uses a cubic function of horsepower.

## Leave-One-Out Cross-Validation

The LOOCV estimate can be automatically computed for any generalized linear model using the glm() and cv.glm() functions.

We can use the glm() function to perform logistic regression by passing in the family="binomial" argument. But if we use glm() to fit a model without passing in the family argument, then it performs linear regression, just like the lm() function.

We will perform linear regression using the glm() function rather than the lm() function because the former can be used together with cv.glm(). The cv.glm() function is part of the boot library.

```{r}
library(boot)
```

```{r}
glm.fit = glm(mpg ~ horsepower, data = Auto)

cv.err = cv.glm(Auto, glm.fit)
cv.err$delta
```
The cv.glm() function produces a list with several components. The two numbers in the delta vector contain the cross-validation results.

Below, we discuss a situation in which the two numbers differ. Our cross-validation estimate for the test error is approximately 24.23.

We can repeat this procedure for increasingly complex polynomial fits. To automate the process, we use the for() function to initiate a for loop which iteratively fits polynomial regressions for polynomials of order i = 1 to i = 5, computes the associated cross-validation error, and stores it in the ith element of the vector cv.error

```{r}
cv.error = rep(0, 5)

for (i in 1:5) {
  glm.fit = glm(mpg ~ poly(horsepower, i), data = Auto)
  cv.error[i] = cv.glm(Auto, glm.fit)$delta[1]
}

cv.error
```

As in Figure 5.4, we see a sharp drop in the estimated test MSE between the linear and quadratic fits, but then no clear improvement from using higher-order polynomials

## k-Fold Cross-Validation


































